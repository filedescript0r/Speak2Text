# app.R
# –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ R:
# install.packages(c("shiny","base64enc","shinyjs","reticulate","dplyr","tidyr","stringr","wordcloud","tm","ggplot2"))

library(shiny)
library(base64enc)
library(shinyjs)
library(reticulate)
library(dplyr)
library(tidyr)
library(stringr)
library(wordcloud)
library(tm)
library(ggplot2)


# -----------------------------
# Python: —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã:
# pip install librosa soundfile numpy scipy transformers whisper torch
# (–µ—Å–ª–∏ GPU: —Å—Ç–∞–≤—å—Ç–µ torch —Å –ø–æ–¥—Ö–æ–¥—è—â–∏–º wheel)
# -----------------------------

# ---------------- Python: –µ–¥–∏–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ --------------
py_run_string("
import json
import numpy as np
import librosa
import os
import sys

# Optional: SER
try:
    from speechbrain.pretrained import EncoderClassifier
    ser_model = EncoderClassifier.from_hparams(
        source='speechbrain/emotion-recognition-wav2vec2-IEMOCAP',
        savedir='ser_model'
    )
except:
    ser_model = None

# =========================================================
# ‚¨áÔ∏è –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø: –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —Å YouTube —á–µ—Ä–µ–∑ yt-dlp
# =========================================================
def download_youtube_audio_py(url, output_path_base):
    try:
        import yt_dlp
    except ImportError:
        print('–û—à–∏–±–∫–∞: –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ yt-dlp –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.', file=sys.stderr)
        return None
    
    # –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞, –∫–æ—Ç–æ—Ä—ã–π yt-dlp —Å–æ–∑–¥–∞—Å—Ç (—Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .wav)
    output_full_path = output_path_base + '.wav'

    # yt-dlp options:
    ydl_opts = {
        'format': 'bestaudio/best',
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –∏–º–µ–Ω–µ–º (yt-dlp –¥–æ–±–∞–≤–∏—Ç .wav –≤ –∫–æ–Ω—Ü–µ)
        'outtmpl': output_path_base, 
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'wav',
            'preferredquality': '192',
        }],
        'quiet': True,
        'nocheckcertificate': True
    }
    
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            # –ó–∞–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏
            ydl.download([url])
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω –∏ –≤–æ–∑–≤—Ä–∞—Ç –ø–æ–ª–Ω–æ–≥–æ –ø—É—Ç–∏
        if os.path.exists(output_full_path):
            return output_full_path
        else:
            print(f'–û—à–∏–±–∫–∞: –§–∞–π–ª {output_full_path} –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω.', file=sys.stderr)
            return None
            
    except Exception as e:
        # –ë–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ –æ—à–∏–±–∫–∏ –≤ –∫–æ–Ω—Å–æ–ª—å R
        print(f'‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ YouTube: {e}', file=sys.stderr)
        return None

# =========================================================
# ‚¨áÔ∏è –°–£–©–ï–°–¢–í–£–Æ–©–ê–Ø –§–£–ù–ö–¶–ò–Ø: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ Librosa
# =========================================================
def extract_librosa_features_py(file_path, sr_target=16000):

    y, sr = librosa.load(file_path, sr=sr_target)

    # RMS
    rms = librosa.feature.rms(y=y)[0]

    # Zero crossing
    zcr = librosa.feature.zero_crossing_rate(y)[0]

    # Spectral centroid
    centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]

    # Spectral bandwidth
    bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]

    # Spectral rolloff
    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.85)[0]

    # Spectral contrast
    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)

    # Chroma
    chroma = librosa.feature.chroma_stft(y=y, sr=sr)

    # Mel spectrogram
    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr)
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)

    # MFCC
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

    # Delta MFCC
    delta_mfcc = librosa.feature.delta(mfcc)

    # Pitch (YIN)
    f0 = librosa.yin(y, fmin=50, fmax=300, sr=sr)
    f0 = f0[np.isfinite(f0)]
    if len(f0) == 0:
        f0 = np.array([0.0])

    # Harmonic / Percussive
    y_harm, y_perc = librosa.effects.hpss(y)

    # Onset strength
    onset_env = librosa.onset.onset_strength(y=y, sr=sr)

    # Tempogram
    tempogram = librosa.feature.tempogram(onset_envelope=onset_env, sr=sr)

    # SER prediction
    ser = None
    if ser_model is not None:
        try:
            ser_out = ser_model.classify_file(file_path)
            ser = {
                'label': ser_out[3],
                'scores': ser_out[1].tolist()
            }
        except:
            ser = None

    return {
        'rms': rms.tolist(),
        'zcr': zcr.tolist(),
        'centroid': centroid.tolist(),
        'bandwidth': bandwidth.tolist(),
        'rolloff': rolloff.tolist(),
        'contrast': contrast.tolist(),
        'chroma': chroma.tolist(),
        'mel_spec_db': mel_spec_db.tolist(),
        'mfcc': mfcc.tolist(),
        'delta_mfcc': delta_mfcc.tolist(),
        'f0': f0.tolist(),
        'harm': y_harm.tolist(),
        'perc': y_perc.tolist(),
        'onset_env': onset_env.tolist(),
        'tempogram': tempogram.tolist(),
        'sr': int(sr),
        'ser': ser
    }
")

# –ø–æ–ª—É—á–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é
extract_librosa_features_py <- py$extract_librosa_features_py
download_youtube_audio_py <- py$download_youtube_audio_py # <--- –í–°–¢–ê–í–ò–¢–¨ –°–Æ–î–ê

# ----------------------------- Whisper Init -----------------------------
whisper <- import("whisper")
model <- tryCatch({
  cat("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper: small ...\n")
  whisper$load_model("small")
}, error=function(e) stop("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ Whisper: ", e$message))

# ----------------------------- Python Sentiment -----------------------------
transformers <- import("transformers")
sentiment_model <- tryCatch({
  cat("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Sentiment (RU)...\n")
  transformers$pipeline("sentiment-analysis", model="blanchefort/rubert-base-cased-sentiment")
}, error = function(e) {
  stop("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä—É—Å—Å–∫–æ–π –º–æ–¥–µ–ª–∏ Sentiment: ", e$message)
})

# ----------------------------- Stopwords -----------------------------
russian_stopwords_extended <- c(
  tm::stopwords("russian"),
  "—ç—Ç–æ","—Ç–æ–ª—å–∫–æ","–º–æ–∂–µ–º","–º–æ–∂–µ—Ç","–¥–æ–ª–∂–Ω—ã","–Ω–∞—à","–∫–ª—é—á","–ª—É—á—à–µ",
  "–Ω–æ–≤—ã—Ö","–ø—Ä–æ—Ü–µ—Å—Å","–≤–µ—Å—å","–¥–∞–∂–µ","–æ—á–µ–Ω—å","—Ç–∞–∫–∂–µ","—á—Ç–æ–±—ã","—Å–µ–∫—É–Ω–¥"
)

# ----------------------------- JS -----------------------------
audio_recorder_js <- '
$(document).ready(function() {
    let mediaRecorder; let audioChunks = []; let stream;
    const startButton = $("#start_rec"); const stopButton = $("#stop_rec"); const statusDiv = $("#recording_status");
    startButton.on("click", function() {
        navigator.mediaDevices.getUserMedia({ audio: true }).then(s => {
            stream = s; mediaRecorder = new MediaRecorder(stream, { mimeType: "audio/webm" }); audioChunks = [];
            mediaRecorder.ondataavailable = event => audioChunks.push(event.data);
            mediaRecorder.onstop = () => {
                const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
                const reader = new FileReader();
                reader.onloadend = function() { Shiny.setInputValue("audio_data", reader.result); statusDiv.text("–ê—É–¥–∏–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è..."); };
                reader.readAsDataURL(audioBlob);
                stream.getTracks().forEach(track => track.stop());
            };
            mediaRecorder.start(); statusDiv.text("üî¥ –ò–¥—ë—Ç –∑–∞–ø–∏—Å—å..."); startButton.prop("disabled", true); stopButton.prop("disabled", false);
        }).catch(err => statusDiv.text("‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É: " + err.name));
    });
    stopButton.on("click", function() {
        if (mediaRecorder && mediaRecorder.state !== "inactive") { mediaRecorder.stop(); statusDiv.text("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏..."); startButton.prop("disabled", false); stopButton.prop("disabled", true); }
    });
    stopButton.prop("disabled", true);
});
'

seek_audio_js <- '
$(document).on("click", ".seekable-word", function(e) {
    e.preventDefault();
    const t = $(this).data("seek-time");
    const p = document.getElementById("audio_player_control");
    if (p && t !== undefined) { p.currentTime = t; p.play(); }
});
'

# ----------------------------- UI -----------------------------
ui <- fluidPage(
  useShinyjs(),
  tags$head(tags$script(HTML(audio_recorder_js)), tags$script(HTML(seek_audio_js))),
  titlePanel("üé§ Audio2Text: SpeakTrack"),
  
  fluidRow(
    column(4,
           actionButton("start_rec","–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å", icon=icon("microphone")),
           actionButton("stop_rec","–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å", icon=icon("stop")),
           fileInput("upload_audio","–ó–∞–≥—Ä—É–∑–∏—Ç—å –∞—É–¥–∏–æ", accept=c(".wav",".mp3",".m4a",".webm")),
           hr(), # –ù–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
           textInput("youtube_url", "YouTube URL", value = "", placeholder = "–í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ YouTube"),
           actionButton("download_youtube","–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å YouTube", icon=icon("cloud-download-alt"))
    ),
    column(8, div(id="recording_status","–û–∂–∏–¥–∞–Ω–∏–µ –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏...", style="font-weight:bold;"))
  ),
  
  hr(),
  
  sidebarLayout(
    sidebarPanel(
      width=6,
      h3("–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏"),
      verbatimTextOutput("transcribed_text"),
      hr(),
      h4("–ê—É–¥–∏–æ"),
      uiOutput("audio_player_ui"),
      hr(),
      verbatimTextOutput("debug_info")
    ),
    mainPanel(
      width=6,
      h3("–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ –Ω–∞–≤–∏–≥–∞—Ü–∏—è"),
      tabsetPanel(
        tabPanel("–ù–∞–≤–∏–≥–∞—Ü–∏—è", tableOutput("seekable_words_table")),
        tabPanel("–û–±–ª–∞–∫–æ —Å–ª–æ–≤", plotOutput("word_cloud_plot", height="350px")),
        tabPanel("Speech & Sentiment",
                 h4("–°–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏ –∏ –ø–∞—É–∑—ã"),
                 verbatimTextOutput("speech_metrics_text")),
        tabPanel("–ê–∫—É—Å—Ç–∏–∫–∞ –≥–æ–ª–æ—Å–∞ (librosa)",
                 h4("–ê–∫—É—Å—Ç–∏—á–µ—Å–∫–∏–µ —Å–≤–æ–¥–∫–∏"), #new
                 verbatimTextOutput("acoustic_summary_text"),
                 hr(),#new
                 
                 h4("RMS energy (—ç–Ω–µ—Ä–≥–∏—è –≥–æ–ª–æ—Å–∞)"),
                 plotOutput("rms_plot"),
                 h4("Zero crossing rate"),
                 plotOutput("zcr_plot"),
                 hr(),
                 h4("Spectral centroid (—è—Ä–∫–æ—Å—Ç—å)"),
                 plotOutput("centroid_plot"),
                 h4("Spectral bandwidth"),
                 plotOutput("bandwidth_plot"),
                 h4("Spectral contrast"),
                 plotOutput("contrast_plot"),
                 h4("Spectral rolloff"),
                 plotOutput("rolloff_plot"),
                 h4("Chroma (heatmap)"),
                 plotOutput("chroma_plot"),
                 hr(),
                 h4("MFCC (13 –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤) - mean"),
                 plotOutput("mfcc_plot"),
                 h4("Delta MFCC (mean)"),
                 plotOutput("delta_mfcc_plot"),
                 hr(),
                 h4("Pitch (YIN) contour"),
                 plotOutput("pitch_plot"),
                 hr(),
                 h4("Onset strength"),
                 plotOutput("onset_env_plot"),
                 h4("Tempogram"),
                 plotOutput("tempogram_plot"),
                 h4("Beat times (vertical lines on onset)"),
                 plotOutput("beat_plot")
        )
      )
    )
  )
)

# ----------------------------- Server -----------------------------
server <- function(input, output, session) {
  
  rv_text <- reactiveVal("")
  rv_words_df <- reactiveVal(NULL)
  rv_audio_path <- reactiveVal(NULL)
  rv_librosa_res <- reactiveVal(NULL)
  
  output$debug_info <- renderPrint({ cat("–ú–æ–¥–µ–ª—å Whisper: small\n") })
  
  # ----------------------------- Librosa wrapper (R calls Python func) -------------
  compute_librosa <- reactive({
    req(rv_audio_path())
    path <- rv_audio_path()
    # –í—ã–∑—ã–≤–∞–µ–º Python —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–∫–∏
    L <- tryCatch({
      py_res <- extract_librosa_features_py(path, 16000L)
      py_res
    }, error = function(e) {
      warning("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ librosa –≤ Python: ", e$message)
      return(NULL)
    })
    if (is.null(L)) return(NULL)
    
    # –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –≤ —É–¥–æ–±–Ω—ã–π R-—Ñ–æ—Ä–º–∞—Ç
    # –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø–æ–ª–µ–π ‚Äî —Å–ø–∏—Å–∫–∏ —á–∏—Å–µ–ª; –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ –≤–µ–∫—Ç–æ—Ä—ã/matrices
    rms <- tryCatch(unlist(L$rms), error=function(e) numeric(0))
    zcr <- tryCatch(unlist(L$zcr), error=function(e) numeric(0))
    frame_energy <- tryCatch(unlist(L$frame_energy), error=function(e) numeric(0))
    centroid <- tryCatch(unlist(L$centroid), error=function(e) numeric(0))
    bandwidth <- tryCatch(unlist(L$bandwidth), error=function(e) numeric(0))
    rolloff <- tryCatch(unlist(L$rolloff), error=function(e) numeric(0))
    onset_env <- tryCatch(unlist(L$onset_env), error=function(e) numeric(0))
    f0 <- tryCatch(unlist(L$f0), error=function(e) numeric(0))
    harm_rms <- tryCatch(unlist(L$harm_rms), error=function(e) numeric(0))
    perc_rms <- tryCatch(unlist(L$perc_rms), error=function(e) numeric(0))
    tempo <- tryCatch(L$tempo, error=function(e) NA)
    beat_times <- tryCatch(unlist(L$beat_times), error=function(e) numeric(0))
    onset_times <- tryCatch(unlist(L$onset_times), error=function(e) numeric(0))
    
    # contrast: list of lists -> matrix (n_bands x frames)
    contrast <- tryCatch({
      m <- do.call(rbind, L$contrast)
      m
    }, error=function(e) matrix(nrow=0,ncol=0))
    chroma <- tryCatch({
      m <- do.call(rbind, L$chroma)
      m
    }, error=function(e) matrix(nrow=0,ncol=0))
    mfcc <- tryCatch({
      m <- do.call(rbind, L$mfcc)
      if (nrow(m) == 13) m else t(m)
    }, error=function(e) matrix(nrow=13,ncol=0))
    delta_mfcc <- tryCatch({
      m <- do.call(rbind, L$delta_mfcc)
      if (nrow(m) == 13) m else t(m)
    }, error=function(e) matrix(nrow=13,ncol=0))
    melspec_db <- tryCatch({
      m <- do.call(rbind, L$melspec_db)
      m
    }, error=function(e) matrix(nrow=0,ncol=0))
    tempogram <- tryCatch({
      m <- do.call(rbind, L$tempogram)
      m
    }, error=function(e) matrix(nrow=0,ncol=0))
    
    res <- list(
      sr = L$sr,
      rms = rms,
      zcr = zcr,
      frame_energy = frame_energy,
      centroid = centroid,
      bandwidth = bandwidth,
      rolloff = rolloff,
      contrast = contrast,
      chroma = chroma,
      mfcc = mfcc,
      delta_mfcc = delta_mfcc,
      melspec_db = melspec_db,
      f0 = f0,
      harm_rms = harm_rms,
      perc_rms = perc_rms,
      onset_env = onset_env,
      tempogram = tempogram,
      tempo = tempo,
      beat_times = beat_times,
      onset_times = onset_times,#remove comma
      ser = L$ser
    )
    
    rv_librosa_res(res)
    res
  })
  
  # ===================
  acoustic_summary <- reactive({
    L <- compute_librosa(); req(L)
    
    # Pitch
    f0 <- as.numeric(L$f0)
    f0 <- f0[f0 > 50 & f0 < 350]
    
    mean_f0 <- if(length(f0)>0) round(mean(f0),1) else NA
    range_f0 <- if(length(f0)>10) round(quantile(f0,0.95)-quantile(f0,0.05),1) else NA
    
    # RMS
    rms <- as.numeric(L$rms)
    rms_db <- 20 * log10(pmax(rms, 1e-9))
    mean_rms <- round(mean(rms_db), 1)
    sd_rms <- round(sd(rms_db), 1)
    
    # NEW: Spectral Features (–ü—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –¥–ª–∏–Ω—É –≤–µ–∫—Ç–æ—Ä–∞ —É–∂–µ –µ—Å—Ç—å - —ç—Ç–æ —Ö–æ—Ä–æ—à–æ)
    mean_zcr <- if(length(L$zcr)>0) round(mean(L$zcr), 3) else NA
    mean_centroid <- if(length(L$centroid)>0) round(mean(L$centroid), 1) else NA
    mean_bandwidth <- if(length(L$bandwidth)>0) round(mean(L$bandwidth), 1) else NA
    
    # NEW: Tempo (–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ!)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ L$tempo —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ —è–≤–ª—è–µ—Ç—Å—è —á–∏—Å–ª–æ–≤—ã–º (–Ω–µ NULL, –Ω–µ NA, –Ω–µ –º–∞—Ç—Ä–∏—Ü–∞)
    if (!is.null(L$tempo) && is.numeric(L$tempo) && length(L$tempo) == 1 && !is.na(L$tempo)) {
      mean_tempo <- round(L$tempo, 1)
    } else {
      mean_tempo <- NA
    }
    
    list(
      mean_f0 = mean_f0,
      range_f0 = range_f0,
      mean_rms = mean_rms,
      sd_rms = sd_rms,
      mean_zcr = mean_zcr,
      mean_centroid = mean_centroid,
      mean_bandwidth = mean_bandwidth,
      mean_tempo = mean_tempo,
      ser = L$ser
    )
  })
  # ==================
  
  # ---------------- Plots for many features ----------------
  output$rms_plot <- renderPlot({
    L <- compute_librosa(); req(L)
    if (length(L$rms) == 0) { plot.new(); title("RMS: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"); return() }
    df <- data.frame(t = seq_along(L$rms), rms = as.numeric(L$rms))
    ggplot(df, aes(t, rms)) + geom_line() + theme_minimal() + labs(title="RMS Energy", x="Frame", y="Energy")
  })
  
  output$zcr_plot <- renderPlot({
    L <- compute_librosa(); req(L)
    if (length(L$zcr) == 0) { plot.new(); title("ZCR: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"); return() }
    df <- data.frame(t = seq_along(L$zcr), zcr = as.numeric(L$zcr))
    ggplot(df, aes(t, zcr)) + geom_line() + theme_minimal() + labs(title="Zero Crossing Rate", x="Frame", y="ZCR")
  })
  
  output$centroid_plot <- renderPlot({
    L <- compute_librosa(); req(L)
    if (length(L$centroid) == 0) { plot.new(); title("Centroid: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"); return() }
    df <- data.frame(t = seq_along(L$centroid), centroid = as.numeric(L$centroid))
    ggplot(df, aes(t, centroid)) + geom_line() + theme_minimal() + labs(title="Spectral Centroid", x="Frame", y="Hz")
  })
  
  output$bandwidth_plot <- renderPlot({
    L <- compute_librosa(); req(L)
    if (length(L$bandwidth) == 0) { plot.new(); title("Bandwidth: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"); return() }
    df <- data.frame(t = seq_along(L$bandwidth), bw = as.numeric(L$bandwidth))
    ggplot(df, aes(t, bw)) + geom_line() + theme_minimal() + labs(title="Spectral Bandwidth", x="Frame", y="Bandwidth")
  })
  
  output$contrast_plot <- renderPlot({
    L <- compute_librosa(); req(L)
    if (is.null(L$contrast) || nrow(L$contrast)==0) { plot.new(); title("Contrast: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"); return() }
    # melt contrast for plotting
    m <- as.data.frame(t(L$contrast))
    colnames(m) <- paste0("band", seq_len(ncol(m)))
    m$frame <- seq_len(nrow(m))
    df <- tidyr::pivot_longer(m, cols = starts_with("band"), names_to="band", values_to="value")
    ggplot(df, aes(frame, value, color=band)) + geom_line() + theme_minimal() + labs(title="Spectral Contrast", x="Frame", y="Contrast")
  })
  
  output$rolloff_plot <- renderPlot({
    L <- compute_librosa(); req(L)
    if (length(L$rolloff) == 0) { plot.new(); title("Rolloff: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"); return() }
    df <- data.frame(t = seq_along(L$rolloff), rolloff = as.numeric(L$rolloff))
    ggplot(df, aes(t, rolloff)) + geom_line() + theme_minimal() + labs(title="Spectral Rolloff", x="Frame", y="Hz")
  })
  
  output$chroma_plot <- renderPlot({
    L <- compute_librosa(); req(L)
    if (is.null(L$chroma) || nrow(L$chroma)==0) { plot.new(); title("Chroma: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"); return() }
    mat <- L$chroma
    # heatmap: chroma rows x frames columns
    image(t(mat[nrow(mat):1, , drop=FALSE]), axes=FALSE)
    title("Chroma (rows: chroma bins, left->right: time)")
  })
  
  output$mfcc_plot <- renderPlot({
    L <- compute_librosa(); req(L)
    if (is.null(L$mfcc) || ncol(L$mfcc) == 0) { plot.new(); title("MFCC: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"); return() }
    mfcc_mean <- apply(L$mfcc, 1, mean, na.rm = TRUE)
    df <- data.frame(coeff = factor(1:length(mfcc_mean)), value = mfcc_mean)
    ggplot(df, aes(coeff, value)) + geom_bar(stat="identity", fill="darkgreen") + theme_minimal() + labs(title="MFCC (mean)", x="MFCC #", y="Mean")
  })
  
  output$delta_mfcc_plot <- renderPlot({
    L <- compute_librosa(); req(L)
    if (is.null(L$delta_mfcc) || ncol(L$delta_mfcc) == 0) { plot.new(); title("Delta MFCC: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"); return() }
    dm <- apply(L$delta_mfcc, 1, mean, na.rm=TRUE)
    df <- data.frame(coeff = factor(1:length(dm)), value = dm)
    ggplot(df, aes(coeff, value)) + geom_bar(stat="identity", fill="orange") + theme_minimal() + labs(title="Delta-MFCC (mean)", x="MFCC #", y="Mean Delta")
  })
  
  
  output$pitch_plot <- renderPlot({
    L <- compute_librosa(); req(L)
    if (length(L$f0) == 0) { plot.new(); title("Pitch: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"); return() }
    df <- data.frame(t = seq_along(L$f0), f0 = as.numeric(L$f0))
    ggplot(df, aes(t, f0)) + geom_line() + theme_minimal() + labs(title="Pitch (YIN)", x="Frame", y="Hz")
  })
  
  output$onset_env_plot <- renderPlot({
    L <- compute_librosa(); req(L)
    if (length(L$onset_env) == 0) { plot.new(); title("Onset env: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"); return() }
    df <- data.frame(t = seq_along(L$onset_env), onset = as.numeric(L$onset_env))
    ggplot(df, aes(t, onset)) + geom_line() + theme_minimal() + labs(title="Onset Strength", x="Frame", y="Strength")
  })
  
  output$tempogram_plot <- renderPlot({
    L <- compute_librosa(); req(L)
    if (is.null(L$tempogram) || nrow(L$tempogram) == 0) { plot.new(); title("Tempogram: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"); return() }
    mat <- L$tempogram
    image(t(mat[nrow(mat):1, , drop=FALSE]), axes=FALSE)
    title("Tempogram")
  })
  
  output$beat_plot <- renderPlot({
    L <- compute_librosa(); req(L)
    # overlay beat times on onset env
    if (length(L$onset_env) == 0) { plot.new(); title("Beats/Onset: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"); return() }
    onset_env <- L$onset_env
    df <- data.frame(t = seq_along(onset_env), onset = as.numeric(onset_env))
    p <- ggplot(df, aes(t, onset)) + geom_line() + theme_minimal() + labs(title="Onset strength + beat times", x="Frame", y="Onset")
    # convert beat times to frames approx: beat_time * sr / hop_length
    if (!is.null(L$beat_times) && length(L$beat_times) > 0 && !is.na(L$sr)) {
      hop_length <- 512
      beat_frames <- round(L$beat_times * L$sr / hop_length)
      for (bf in beat_frames) p <- p + geom_vline(xintercept = bf, color="red", linetype="dashed", alpha=0.6)
    }
    print(p)
  })
  
  # ----------------------------- AUDIO PROCESSING (Whisper) -----------------------------
  process_audio <- function(audio_path){
    rv_audio_path(audio_path)
    
    showNotification("Whisper: –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏...", duration=NULL, id="wh_notify")
    
    total_dur <- as.numeric(system(sprintf('ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 \"%s\"', audio_path), intern=TRUE))
    if (is.na(total_dur)) total_dur <- 0
    n_seg <- ceiling(total_dur / 20)
    if (n_seg < 1) n_seg <- 1
    words_all <- list(); full_text <- ""
    
    for (i in 0:(n_seg-1)) {
      seg_file <- tempfile(fileext=".wav")
      start_time <- i*20
      system(sprintf('ffmpeg -y -i \"%s\" -ss %f -t 20 \"%s\"', audio_path, start_time, seg_file), ignore.stdout=TRUE, ignore.stderr=TRUE)
      
      seg_tr <- tryCatch({ model$transcribe(seg_file, fp16=FALSE, language="ru", word_timestamps=TRUE) }, error=function(e) NULL)
      if (is.null(seg_tr)) next
      full_text <- paste(full_text, seg_tr$text)
      
      if (!is.null(seg_tr$segments)) {
        for (s in seg_tr$segments) {
          if (!is.null(s$words)) {
            seg_words <- do.call(rbind, lapply(s$words, function(w) {
              data.frame(word=as.character(w$word),
                         start=as.numeric(w$start)+start_time,
                         end=as.numeric(w$end)+start_time,
                         stringsAsFactors=FALSE)
            }))
            words_all[[length(words_all)+1]] <- seg_words
          } else {
            # fallback: –µ—Å–ª–∏ –Ω–µ—Ç word-level, —Ä–∞–∑–±–∏–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç
            tokens <- unlist(strsplit(as.character(s$text), '\\\\s+'))
            tokens <- tokens[tokens!=""]
            if (length(tokens) > 0) {
              seg_words <- data.frame(word=tokens,
                                      start=rep(as.numeric(s$start)+start_time, length(tokens)),
                                      end=rep(as.numeric(s$end)+start_time, length(tokens)),
                                      stringsAsFactors=FALSE)
              words_all[[length(words_all)+1]] <- seg_words
            }
          }
        }
      }
    }
    
    removeNotification(id="wh_notify")
    rv_text(full_text)
    
    if (length(words_all) == 0) {
      rv_words_df(data.frame(word=character(0), start=numeric(0), end=numeric(0)))
      return(invisible(NULL))
    }
    
    words_df <- do.call(rbind, words_all)
    words_df <- words_df %>%
      mutate(word_raw=word,
             word=str_to_lower(word),
             word=str_trim(word),
             word=str_replace_all(word,"[^–∞-—è—ë0-9]","")) %>%
      filter(word!="",!is.na(start))
    rv_words_df(words_df)
  }
  
  # ------------------ –∑–∞–ø–∏—Å—å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ ------------------
  observeEvent(input$audio_data,{
    req(input$audio_data)
    output$audio_player_ui <- renderUI({ tags$audio(src=input$audio_data, controls=TRUE, id="audio_player_control") })
    b64 <- gsub("^data:audio/[^;]+;base64,", "", input$audio_data)
    audio_raw <- base64decode(b64)
    webm_file <- tempfile(fileext=".webm"); writeBin(audio_raw, webm_file)
    wav_file <- tempfile(fileext=".wav")
    system(sprintf('ffmpeg -y -f webm -i \"%s\" -ar 16000 -ac 1 \"%s\"', webm_file, wav_file))
    process_audio(wav_file)
    # —Ç–∞–∫–∂–µ –∑–∞–ø—É—Å–∫–∞–µ–º librosa –∞–Ω–∞–ª–∏–∑ –Ω–∞ –ø–æ–ª–Ω–æ–º wav
    try({ compute_librosa() }, silent=TRUE)
  })
  
  # ------------------ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª ------------------
  observeEvent(input$upload_audio,{
    req(input$upload_audio)
    file_path <- input$upload_audio$datapath
    
    mime_type <- switch(tolower(tools::file_ext(input$upload_audio$name)),
                        "wav"="audio/wav","mp3"="audio/mpeg","m4a"="audio/mp4","webm"="audio/webm","audio/wav")
    # —Å–æ–∑–¥–∞—ë–º data URL –¥–ª—è –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–Ω–∏—è –≤ –±—Ä–∞—É–∑–µ—Ä–µ
    audio_dataurl <- base64enc::dataURI(file=file_path, mime=mime_type)
    
    output$audio_player_ui <- renderUI({
      tags$audio(src=audio_dataurl, type=mime_type, controls=TRUE, id="audio_player_control")
    })
    
    process_audio(file_path)
    # –∑–∞–ø—É—Å–∫–∞–µ–º librosa –∞–Ω–∞–ª–∏–∑ (–ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª)
    try({ compute_librosa() }, silent=TRUE)
  })
  
  #YOUTUBE
  observeEvent(input$download_youtube, {
    url <- input$youtube_url; req(url)
    
    # 1. –ò–Ω–¥–∏–∫–∞—Ü–∏—è –∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞
    showNotification("YouTube: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ...", duration=NULL, id="yt_notify", type="default")
    disable("download_youtube")
    
    # 2. –í—ã–±–æ—Ä –ø—É—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è, yt-dlp –¥–æ–±–∞–≤–∏—Ç .wav
    temp_wav_path_base <- tempfile(fileext = "") 
    
    # 3. –í—ã–∑–æ–≤ Python-—Ñ—É–Ω–∫—Ü–∏–∏
    # –ü–æ—Å–∫–æ–ª—å–∫—É yt-dlp –¥–æ–±–∞–≤–ª—è–µ—Ç .wav, –∏—Ç–æ–≥–æ–≤—ã–π –ø—É—Ç—å –±—É–¥–µ—Ç temp_wav_path_base.wav
    wav_path <- download_youtube_audio_py(url, temp_wav_path_base)
    
    removeNotification(id="yt_notify")
    enable("download_youtube")
    
    if (is.null(wav_path) || !file.exists(wav_path)) {
      showNotification("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ YouTube.", type="error")
      return(NULL)
    }
    
    # 4. –ü—Ä–æ–∏–≥—Ä—ã–≤–∞—Ç–µ–ª—å
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–π WAV-—Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–∏–≥—Ä—ã–≤–∞—Ç–µ–ª—è
    audio_dataurl <- base64enc::dataURI(file=wav_path, mime="audio/wav")
    output$audio_player_ui <- renderUI({
      tags$audio(src=audio_dataurl, type="audio/wav", controls=TRUE, id="audio_player_control")
    })
    
    # 5. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ
    process_audio(wav_path)
    
    # 6. Librosa –∞–Ω–∞–ª–∏–∑
    try({ compute_librosa() }, silent=TRUE)
    
    showNotification(paste("‚úÖ –ê—É–¥–∏–æ —Å YouTube –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ. –î–ª–∏–Ω–∞ —Ñ–∞–π–ª–∞:", round(file.size(wav_path)/1024^2, 2), "–ú–ë"), type="default")
  })
  #YOUTUBE
  
  # ----------------------------- –ù–∞–≤–∏–≥–∞—Ü–∏—è –ø–æ —Å–ª–æ–≤–∞–º -----------------------------
  word_counts_seekable <- reactive({
    words_df <- rv_words_df(); req(words_df)
    df <- words_df %>%
      filter(!word %in% russian_stopwords_extended) %>%
      filter(str_detect(word,"^[–∞-—è—ë]+$")) %>%
      group_by(word) %>%
      summarise(–ß–∞—Å—Ç–æ—Ç–∞=n(), –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ_–í—Ä–µ–º—è=min(start, na.rm=TRUE), .groups="drop") %>%
      arrange(desc(–ß–∞—Å—Ç–æ—Ç–∞), –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ_–í—Ä–µ–º—è) %>%
      head(50) %>%
      rename(–°–ª–æ–≤–æ=word)
    df
  })
  
  output$seekable_words_table <- renderTable({
    df <- word_counts_seekable(); req(df)
    fmt_time <- function(sec) sprintf("%02d:%02d", floor(sec/60), round(sec%%60))
    df$–°–ª–æ–≤–æ <- sapply(seq_len(nrow(df)), function(i)
      as.character(tags$a(df$–°–ª–æ–≤–æ[i], href="#", class="seekable-word",
                          `data-seek-time`=df$–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ_–í—Ä–µ–º—è[i],
                          style="color:blue;cursor:pointer;text-decoration:underline;")))
    df$–í—Ä–µ–º—è <- fmt_time(df$–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ_–í—Ä–µ–º—è)
    df %>% select(–°–ª–æ–≤–æ, –ß–∞—Å—Ç–æ—Ç–∞, –í—Ä–µ–º—è)
  }, sanitize.text.function=function(x)x)
  
  # ----------------------------- –û–±–ª–∞–∫–æ —Å–ª–æ–≤ -----------------------------
  output$word_cloud_plot <- renderPlot({
    df <- word_counts_seekable(); req(df)
    words <- df$–°–ª–æ–≤–æ; freqs <- df$–ß–∞—Å—Ç–æ—Ç–∞
    if(length(words)==0) return(NULL)
    par(mar=c(0,0,0,0))
    wordcloud(words=words, freq=freqs, min.freq=1, max.words=100, random.order=FALSE)
  })
  
  output$transcribed_text <- renderPrint({ rv_text() })
  
  # ----------------------------- WPM –∏ –ø–∞—É–∑—ã -----------------------------
  speech_metrics <- reactive({
    words_df <- rv_words_df(); req(words_df)
    total_words <- nrow(words_df)
    total_time <- max(words_df$end, na.rm=TRUE) - min(words_df$start, na.rm=TRUE)
    if (total_time <= 0) total_time <- 1
    wpm <- total_words / (total_time / 60)
    words_df <- words_df %>% arrange(start)
    pauses <- diff(words_df$start)
    long_pauses <- pauses[pauses>1]
    list(WPM=round(wpm,1), AvgPause=if(length(pauses)>0) round(mean(pauses),2) else NA,
         LongPauses=length(long_pauses), Pauses=pauses)
  })
  
  ###NEW
  # ----------------------------- –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ -----------------------------
  text_complexity_metrics <- reactive({
    words_df <- rv_words_df(); req(words_df)
    
    # 1. –£–±–∏—Ä–∞–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞
    # (–≠—Ç–æ —É–∂–µ –¥–µ–ª–∞–µ—Ç—Å—è –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–ª–æ–≤, –Ω–æ –ª—É—á—à–µ –ø–µ—Ä–µ—Å—Ç—Ä–∞—Ö–æ–≤–∞—Ç—å—Å—è)
    clean_words <- words_df$word
    
    total_words <- nrow(words_df)
    unique_words <- length(unique(clean_words))
    
    # Type-Token Ratio (TTR): (–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ / –û–±—â–µ–µ —á–∏—Å–ª–æ —Å–ª–æ–≤) * 100
    TTR <- if (total_words > 0) round((unique_words / total_words) * 100, 2) else 0
    
    # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º word_raw –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞ –¥–ª–∏–Ω—ã, –≤–∫–ª—é—á–∞—è –ø—Ä–æ–±–µ–ª—ã/–∑–∞–ø—è—Ç—ã–µ, 
    # –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏, –Ω–æ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—á–∏—â–µ–Ω–Ω–æ–µ —Å–ª–æ–≤–æ
    mean_word_length <- round(mean(nchar(clean_words)), 2)
    
    list(
      total_words = total_words,
      unique_words = unique_words,
      TTR = TTR,
      mean_word_length = mean_word_length
    )
  })
  ###NEW
  
  output$speech_metrics_text <- renderPrint({
    metrics <- speech_metrics()
    cat("WPM:", metrics$WPM, "\n")
    cat("–°—Ä–µ–¥–Ω—è—è –ø–∞—É–∑–∞ (—Å–µ–∫):", metrics$AvgPause, "\n")
    cat("–î–ª–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—É–∑—ã (>1 —Å–µ–∫):", metrics$LongPauses, "\n")
  })
  
  
  # ----------------------------- Sentiment Analysis -----------------------------
  sentiment_analysis <- reactive({
    text <- rv_text(); req(text)
    res <- sentiment_model(text)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ R-—Ç–∞–±–ª–∏—Ü—É
    df <- data.frame(
      label = sapply(res, function(x) x$label),
      score = sapply(res, function(x) x$score)
    )
    
    # –ù–∞—Ö–æ–¥–∏–º —Å—Ç—Ä–æ–∫—É —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º score
    best_sentiment <- df[which.max(df$score), ]
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º (–¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤) –∏ –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    list(
      data = df,
      best_label = best_sentiment$label,
      best_score = best_sentiment$score
    )
  })
  
  output$sentiment_table <- renderTable({ sentiment_analysis()$data })
  
  #new
  output$acoustic_summary_text <- renderPrint({
    s <- acoustic_summary(); req(s)
    
    cat("--- –û—Å–Ω–æ–≤–Ω—ã–µ –∞–∫—É—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ ---\n")
    cat("–°—Ä–µ–¥–Ω–∏–π Pitch (F0), –ì—Ü:", s$mean_f0, "\n")
    cat("–î–∏–∞–ø–∞–∑–æ–Ω Pitch, –ì—Ü:", s$range_f0, "\n")
    cat("–°—Ä–µ–¥–Ω—è—è RMS (–¥–ë):", s$mean_rms, "\n")
    cat("–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ RMS:", s$sd_rms, "\n")
    
    cat("\n--- –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ ---\n")
    cat("–°—Ä. ZCR (—à—É–º/–∑–≤–æ–Ω–∫–æ—Å—Ç—å):", s$mean_zcr, "\n")
    cat("–°—Ä. Centroid (—è—Ä–∫–æ—Å—Ç—å), –ì—Ü:", s$mean_centroid, "\n")
    cat("–°—Ä. Bandwidth (—à–∏—Ä–∏–Ω–∞ —Å–ø–µ–∫—Ç—Ä–∞), –ì—Ü:", s$mean_bandwidth, "\n")
    
    cat("\n--- –†–∏—Ç–º –∏ —Å–∫–æ—Ä–æ—Å—Ç—å ---\n")
    cat("Tempo (BPM):", if (is.na(s$mean_tempo)) "–ù/–î" else s$mean_tempo, "\n") # <-- –£—Å–ª–æ–≤–Ω—ã–π –≤—ã–≤–æ–¥
    
    if (!is.null(s$ser)) {
      cat("\nSpeech Emotion Recognition (SER):\n")
      cat("–≠–º–æ—Ü–∏—è:", s$ser$label, "\n")
      cat("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:", paste(round(s$ser$scores,3), collapse=", "), "\n")
    }
  })
  #new
  #new
  output$speech_metrics_text <- renderPrint({
    metrics <- speech_metrics()
    comp <- text_complexity_metrics()
    sent <- sentiment_analysis() # <-- –í—ã–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    
    cat("--- –ú–µ—Ç—Ä–∏–∫–∏ —Ç–µ–º–ø–∞ –∏ –ø–∞—É–∑ ---\n")
    cat("WPM (—Å–ª–æ–≤ –≤ –º–∏–Ω—É—Ç—É):", metrics$WPM, "\n")
    cat("–°—Ä–µ–¥–Ω—è—è –ø–∞—É–∑–∞ (—Å–µ–∫):", metrics$AvgPause, "\n")
    cat("–î–ª–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—É–∑—ã (>1 —Å–µ–∫):", metrics$LongPauses, "\n")
    
    cat("\n--- –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ ---\n")
    cat("–û–±—â–µ–µ —á–∏—Å–ª–æ —Å–ª–æ–≤ (Tokens):", comp$total_words, "\n")
    cat("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ (Types):", comp$unique_words, "\n")
    cat("TTR (–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ), %:", comp$TTR, "\n")
    cat("–°—Ä. –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞ (—Å–∏–º–≤–æ–ª–æ–≤):", comp$mean_word_length, "\n")
    
    cat("\n--- –û—Å–Ω–æ–≤–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å ---\n")
    cat("–≠–º–æ—Ü–∏—è:", sent$best_label, "\n")
    cat("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:", round(sent$best_score, 4), "\n") # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫—É
  })
  #new
  
}

shinyApp(ui, server)
